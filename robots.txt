# This is a robots.txt file.
#
# This file tells search engines which parts of your website they can and cannot crawl.

User-agent: *
Disallow: /admin
Disallow: /api
Disallow: /sitemap.xml

# Allow Google AdSense to crawl all pages.
Allow: /